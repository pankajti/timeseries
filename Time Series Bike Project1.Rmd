---
title: "Time Series Bike Project"
author: "Kay Ayala"
date: "4/10/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Rubric 

1. Pick a data set that has two or more variables recorded over time (similar to the Schumway LA air quality data from Unit 12. (dataset: lap from package: astsa) (can’t use this one  )
2. Select a response from the data set.  
3.  Be creative and come up with a scenario as to why a client would want to analyze this data and why this response is important!  Or better yet, use a real problem that you are interested in!
4. Fit at least one model from each of the following four categories (provide all plots and tables needed to ID these models: acfs, spectral density, factor tables, etc.):
	a. ARMA / ARIMA / ARUMA / Signal Plus Noise (univariate analysis)
	b. VAR with at least one explanatory model.
	c.  Neural Network
	d. Ensemble model using at least two of the above.  (this model does not have to “beat” your other models.
5. Compare all models with the ASE… this does not mean you have to choose the model with the lowest ASE. 
6. Pick a forecast horizon based on your “problem” from part 3 above and provide the forecasts and prediction limits.  
7. Create a ppt and a 7-minute video describing your analysis and steps 1 – 6 above.   
8. Post that video to you-Tube and the (private) link to the Google-Doc and submit your ppt and Rmd File (or Jupyter notebook) to 2DS.  Please leave the link on the Google Doc for a week so others can learn from your presentation.  Please check out at least 3 of your peer’s presentations and please watch your own presentation as well.   It is often very useful (although always a bit awkward for me at least ;) to watch yourself present!

## Time Series Bike Share Project

This is an analysis of Capital Bikeshare data from Washington D.C. over two years. 

"Bike sharing systems are a new generation of traditional bike rentals where the whole process from membership, rental and return back has become automatic. Through these systems, user is able to easily rent a bike from a particular position and return back to another position. Currently, there are about over 500 bike-sharing programs around the world which are composed of over 500 thousands bicycles. Today, there exists great interest in these systems due to their important role in traffic, environmental and health issues.

Apart from interesting real-world applications of bike sharing systems, the characteristics of data being generated by these systems make them attractive for the research. Opposed to other transport services such as bus or subway, the duration of travel, departure and arrival position is explicitly recorded in these systems. This feature turns bike sharing system into a virtual sensor network that can be used for sensing mobility in the city. Hence, it is expected that most of important events in the city could be detected via monitoring these data." - [Kaggle](https://www.kaggle.com/marklvl/bike-sharing-dataset#hour.csv)


#### Imports
```{r imports, results='hide', message = FALSE}
suppressMessages(library(tswge))
suppressMessages(library(tidyverse))
suppressMessages(library(plotly))
suppressMessages(library(xts))
suppressMessages(library(vars))
suppressMessages(library(nnfor))
```

#### Mission Statement

We are fictive members of the city of D.C's. Department of Transportation. We are interested knowing about bike usage patterns in the city for our congestion and events initiative. We were able to find this bike share data and we assume the results of our analysis will generalize to non-bike share members. We understand this is purely a case study it may not accurately represent the entire bike population of Washington D.C. 

We have major road construction happening in the next six months and need to report the expected impact on the biking populace over this time. The feature of interest we would like to predict is "Total Users". The horizon we will be predicting over is the next six months. Since we are interested in more long term and gross trends we are reducing our data from an hourly sample rate to a daily average.  

#### Load Data
```{r load data, message=FALSE}

bike_data = read_csv('/Users/kaileyayala/Documents/Time Series/bike data.csv')
head(bike_data)
```

We can see above we have a variety of features to be working with here. We have: Date, Season, Hour, Holiday, Day of the Week, Working Day, Weather Type, Temperature F, Temperature Feels F, Humidity, Wind Speed, Casual Users, Registered Users, Total Users. Since we are trying to forecast, the features we will retain for these predictions are the ones we can reasobably expect to be able to predict. We won't be building models for these features. Instead we will assume we already have them on hand. 

The features we will be using for our analysis are Temperature Feels F which is a metric of what the temperature feels like. Since this is going to be colinear with temperature and humidity those have been omitted. The other feature we are going to be using is Wind Speed. 

``` {r average by day}
daily_avg = aggregate(bike_data[c("Total Users", "Wind Speed", "Temperature Feels F")], by = list(bike_data$Date), FUN = mean)
d = daily_avg
daily_avg = d[order(as.Date(d$Group.1, format="%m/%d/%Y")),]

rownames(daily_avg) <- 1:nrow(daily_avg)
daily_avg = data.frame(daily_avg)
colnames(daily_avg) = c("Date", "Total Users", "Wind Speed", "Temp. Feels F")
daily_avg= subset(daily_avg, select=c("Temp. Feels F", "Wind Speed", "Total Users")) 

plot.ts(daily_avg)

bike_data = daily_avg

bikeTest = data.frame(bike_data$"Temp. Feels F"[550:731], 
                    bike_data$"Wind Speed"[550:731],
                    bike_data$"Total Users"[550:731])

colnames(bikeTest) = c("Temp. Feels F", "Wind Speed",  "Total Users")

bikeTrain = data.frame(bike_data$"Temp. Feels F"[0:548],
                     bike_data$"Wind Speed"[0:548], 
                     bike_data$"Total Users"[0:548])
colnames(bikeTrain) = c("Temp. Feels F", "Wind Speed",  "Total Users")

head(bike_data)
```



#### Check for Stationarity

To determine which models are most reasonable, we must inspect stationarity. 

```{r stationary, result = 'hide', message= FALSE}
Total_Users = bike_data$`Total Users`
plot_ = plotts.sample.wge(Total_Users)

first_half = bike_data$`Total Users`[1:(length(bike_data$`Total Users`)/2)]
second_half = bike_data$`Total Users`[(length(bike_data$`Total Users`)/2+1):(length(bike_data$`Total Users`))]

acf(first_half)
acf(second_half)
```

The mean of the realization appears to be varying based on time. This is because it looks like there is seasonality on the order of roughly one year and that seasonality makes the change in trend over time more apparent. However we can't be sure this is trend or if this is just wandering especially since our dataset is so short. We only have one realization of total users because of the nature of the dataset so we can't average realizations to have a better estimation of this either. We will be investigating stationary models of the data. [to do: change this to non-stationary and add models. ]

It's hard to tell if there is change in variance over time since we have only one realization. It appears there may be smaller variance at the beginning of the realization and larger variance towards the end. However for now we will assume the data is stationary.  [to do: change this to non-stationary and add models. ]

The slow decay of the ACF is indicative of non-stationarity. 
The first and second halves are slightly different. This is an indicator of non-stationary data. 

to do: 
Comment on ACF to determine possible model type. 
Comment on spectral density to determine model type. 

We can see from the spectral density there is a peak at zero which is indicative of wandering.



#### ARMA Model

We want to see what an ARMA model does with this data. 

to do: fix this so the forcast isn't predicting with lastn. Instead it should be a test/train set. 

```{r ARMA Model 1 }

# acfs, spectral density, factor tables, etc.
# to do 

# ARMA Model:

aic5.wge(bikeTrain$"Total Users") # picks p=2, q=1 
aic5.wge(bikeTrain$"Total Users", type='bic') # picks p=2, q=1

# both AIC and BIC agree on ARMA(2,1)

est_bike_arma = est.arma.wge(bikeTrain$`Total Users`, p=2, q=1)

plot_ = plotts.sample.wge(est_bike_arma$res, arlimits = TRUE)
```

We can see the ACF looks like white noise. Though the realization of the residuals looks like it still has something in it. It looks like the variance of the residuals depends on time. The spectral density doesn't have much wandering anymore. Though it still looks to have more large peaks than I would expect white noise to have. 

```{r ARMA ljung, result='hide', message= FALSE}
ljung24 = ljung.wge(est_bike_arma$res,p=2,q=1)
ljung48 = ljung.wge(est_bike_arma$res,p=2,q=1,K=48)

ljung24$pval #0.6801141
ljung48$pval #0.0829797
```

The ljung-box test with k of 24 and 48 give us p-values respectively of 0.68 and 0.08. This means there is not sufficient evidence to reject the null hypothesis of white noise. This means we don't have evidence for the residuals being correlated. 


```{r ARMA Model 2, results='hide', message=FALSE }
for_bike_arma= fore.arma.wge(bikeTrain$`Total Users`, phi=est_bike_arma$phi, theta = est_bike_arma$theta, n.ahead= 182 , limits = T , lastn=F )
```

The forcast does not look representative of the data. The gradual return to the mean is expected from this kind of model but right off the bat it looks like we could do a lot better with other kinds of models. 

```{r ARMA Model 3, results='hide', message=FALSE }

total_users = bike_data$`Total Users`
len_total_users = length(total_users)

plot(x= seq((len_total_users -182 ), len_total_users) , y = 
       total_users[(len_total_users -182 ): len_total_users], type='l')

lines(x= seq((len_total_users -182+1 ), len_total_users) , y = for_bike_arma$f,
      type= "l", col = 'blue')

lines(x= seq((len_total_users -182+1 ), len_total_users) , y = for_bike_arma$ll,
      type= "l", col = 'blue')

lines(x= seq((len_total_users -182+1 ), len_total_users) , y = for_bike_arma$ul,
      type= "l", col = 'blue')

```

This is a close up on the forecast. We can see the confidence intervals are very wide and the forecast doesn't folow the realization very well. 

```{r ARMA Model 4 }

ASE_ARMA21 = mean((for_bike_arma$f - bike_data$`Total Users`[(length(bike_data$`Total Users`) -182+1 ): length(bike_data$`Total Users`)])^2)
ASE_ARMA21
```

Our ASE from this model is 4586. This is now our benchmark for the other models' performance. 


#### ARIMA Model

Now we want to try a Non-stationary model. Let's see what an ARIMA does with this. 

```{r ARIMA model 1, eval = TRUE}
### ARIMA model 

bike_tr1 = artrans.wge(bikeTrain$`Total Users`, phi = 1)

```

The first difference removed the slowly damping behavior from the autocorrelations very well. 

```{r ARIMA model 2, results = 'hide', message=FALSE, eval = TRUE}
aic_ARIMA = aic5.wge(bike_tr1) # picks p=1, q=1
bic_ARIMA = aic5.wge(bike_tr1, type='bic') # picks p=1, q=1
```
```{r ARIMA model 3, eval = TRUE}
aic_ARIMA
bic_ARIMA
#both AIC and BIC pick ARMA(1,1)
```
Both the AIC and BIC chose p=1 and q=1. 

```{r ARIMA model 4, eval = TRUE}
est_bike_arima = est.arma.wge(bike_tr1, p=1, q=1)

Residual_Diagnostic_Plot_ARIMA = plotts.sample.wge(est_bike_arima$res, arlimits = TRUE)

```
```{r ARIMA ljung 1, result='hide', message= FALSE}
ljung24 = ljung.wge(est_bike_arima$res,p=1,q=1)
ljung48 = ljung.wge(est_bike_arima$res,p=1,q=1,K=48)
```
```{r ARIMA ljung 2}
print(ljung24$pval) #0.12787
print(ljung48$pval) #0.01794144
```

The ljung-box test with k of 24 and 48 give us p-values respectively of 0.13 and 0.02. This means there is an unclear result there is evidence both for and against white noise.  


```{r ARIMA model 5, eval = TRUE}

for_bike_arima= fore.aruma.wge(bikeTrain$`Total Users`, phi=est_bike_arima$phi, 
                               theta = est_bike_arima$theta, d=1, 
                               n.ahead= 182 , limits = T , lastn=F )
```

```{r ARIMA model 6, eval = TRUE}

total_users = bike_data$`Total Users`
len_total_users = length(total_users)

plot(x= seq((len_total_users -182 ), len_total_users) , y = 
       total_users[(len_total_users -182 ): len_total_users], type='l')
lines(x= seq((len_total_users -182 ), len_total_users) , y = 
        total_users[(len_total_users -182 ): len_total_users], type='l')

lines(x= seq((len_total_users -182+1 ), len_total_users) , y = for_bike_arima$f,
      type= "l", col='blue')

lines(x= seq((len_total_users -182+1 ), len_total_users) , y = for_bike_arima$ul,
      type= "l", col='blue')

lines(x= seq((len_total_users -182+1 ), len_total_users) , y = for_bike_arima$ll,
      type= "l", col='blue')

```

Again we can see the forcast doesn't match the residuals very well. 

```{r ARIMA model 7, eval = TRUE}

ASE2_ARIMA111 = mean((for_bike_arima$f - total_users[(len_total_users -182+1 ): len_total_users])^2)
ASE2_ARIMA111

# Compare all models with the ASE… this does not mean you have to choose the model with the lowest ASE.
# Pick a forecast horizon based on your “problem” from part 3 above and provide the forecasts and prediction limits.  
```

The ASE for this ARIMA(1,1,1) model is 5382. This was even larger than the ASE for the ARMA model. 

#### ARUMA Model

Now we want to try a Non-stationary model. Let's see what an ARUMA does with this. 

```{r ARUMA model 1, eval = TRUE}

### ARUMA model 

bike_tr365 = artrans.wge(bikeTrain$`Total Users`, phi.tr = c(rep(0,364),1))
bike_tr365.1 = artrans.wge(bike_tr365, phi = 1)
```

The first difference removed the slowly damping behavior from the autocorrelations very well. 

```{r ARUMA model 2, results = 'hide', message=FALSE, eval = TRUE}

bic_ARUMA = aic5.wge(bike_tr365.1, type='bic') # picks p=0, q=1
```
```{r ARUMA model 3, eval = TRUE}

bic_ARUMA

```
Both the AIC and BIC chose p=1 and q=1. 

```{r ARUMA model 4, eval = TRUE}
est_bike_arima = est.arma.wge(bike_tr365.1, p=0, q=1)

Residual_Diagnostic_Plot_ARUMA = plotts.sample.wge(est_bike_arima$res, arlimits = TRUE)

```
```{r ARUMA ljung 1, result='hide', message= FALSE}
ljung24 = ljung.wge(est_bike_arima$res,p=0,q=1)
ljung48 = ljung.wge(est_bike_arima$res,p=0,q=1,K=48)
```
```{r ARUMA ljung 2}
print(ljung24$pval) #0.004088722
print(ljung48$pval) #4.988254e-05
```

The ljung-box test with k of 24 and 48 give us p-values near zero. This is strong evidence to reject the null hypothesis of white noise. 


```{r ARUMA model 5, eval = TRUE}

for_bike_arima= fore.aruma.wge(bikeTrain$`Total Users`, phi=est_bike_arima$phi, 
                               theta = est_bike_arima$theta, d=1, 
                               n.ahead= 182 , limits = T , lastn=F )
```

```{r ARUMA model 6, eval = TRUE}

total_users = bike_data$`Total Users`
len_total_users = length(total_users)

plot(x= seq((len_total_users -182 ), len_total_users) , y = 
       total_users[(len_total_users -182 ): len_total_users], type='l')
lines(x= seq((len_total_users -182 ), len_total_users) , y = 
        total_users[(len_total_users -182 ): len_total_users], type='l')

lines(x= seq((len_total_users -182+1 ), len_total_users) , y = for_bike_arima$f,
      type= "l", col='blue')

lines(x= seq((len_total_users -182+1 ), len_total_users) , y = for_bike_arima$ul,
      type= "l", col='blue')

lines(x= seq((len_total_users -182+1 ), len_total_users) , y = for_bike_arima$ll,
      type= "l", col='blue')

```

Again we can see the forcast doesn't match the residuals very well. 

```{r ARUMA model 7, eval = TRUE}

ASE2_ARUMA011 = mean((for_bike_arima$f - total_users[(len_total_users -182+1 ): len_total_users])^2)
ASE2_ARUMA011

# Compare all models with the ASE… this does not mean you have to choose the model with the lowest ASE.
# Pick a forecast horizon based on your “problem” from part 3 above and provide the forecasts and prediction limits.  
```

The ASE for this ARIMA(1,1,1) model is 5382. This was even larger than the ASE for the ARMA model. 

## VAR

```{r VAR new, eval = TRUE}

X = bikeTrain + 0.01
bikeTest = bikeTest + 0.01
type_ = "const"

```

```{r VARselect, results='hide', message=FALSE, eval = TRUE}
VARselect(X, lag.max = 50, type = type_, season = NULL, exogen = NULL)
#VARselect picks p=2 (using  BIC)
```

```{r VAR plot, eval = TRUE}
lsfit=VAR(X,p=8,type=type_)
preds=predict(lsfit,n.ahead=182)

par(mar=c(1,1,1,1))
#library(RColorBrewer)
#fanchart(preds, colors = brewer.pal(n = 8, name = "Blues")) # Change color pallet to make distinguishable. 

t = c(1:182)
plot(t, preds$fcst$Total.Users[1:182],  type='l',col="blue", ylim=c(0,450))
lines(t, bikeTest$"Total Users",col="black")
lines(t, preds$fcst$Total.Users[183:364], col="blue")
lines(t, preds$fcst$Total.Users[365:546],  col="blue")
```
We can see the Var plot doesn't do much better than the ARMA or ARIMA from visual inspection. The prediction again is just a gently curved line that doesn't follow the realization very well. 

```{r VAR fit, eval = TRUE}

AIC(lsfit)

ASE_VAR = mean((preds$fcst$Total.Users[1:182]-bikeTest$"Total Users")^2)
ASE_VAR 


# Compare all models with the ASE… this does not mean you have to choose the model with the lowest ASE. 
# Pick a forecast horizon based on your “problem” from part 3 above and provide the forecasts and prediction limits.  

```
The VAR ASE of 5695 is higher than either the ARMA or ARIMA model. 

#### Neural Network
```{r Neural Network 1, eval = TRUE }

temp_Feels = ts(daily_avg$"Temp. Feels F")
wind_Speed = ts(daily_avg$"Wind Speed")
total_users = ts(bikeTrain$"Total Users")
xVars = data.frame(temp_Feels, wind_Speed)

set.seed(2)
fit.mlp = mlp(total_users, xreg = xVars)

fit.mlp
plot(fit.mlp)

fore.mlp = forecast(fit.mlp, h=182,  xreg = xVars)
plot(fore.mlp)

```
```{r Neural Network Plot, eval=TRUE}

total_users = bike_data$"Total Users"

plot(x= seq((len_total_users -182 ), len_total_users) , y = 
       total_users[(len_total_users -182 ): len_total_users], type='l')

lines(x= seq((len_total_users -182+1 ), len_total_users) , y = fore.mlp$mean,
      type= "l", col='blue')

```


```{r Neural Network 2, eval =TRUE}
#total_users_test = ts(daily_avg$"Total Users"[549:731], start = 549)
total_users_test = ts(bikeTest$`Total Users`, start = 549)

ASE_NN = mean((total_users_test  - fore.mlp$mean)^2)
ASE_NN

# Compare all models with the ASE… this does not mean you have to choose the model with the lowest ASE. 
# Pick a forecast horizon based on your “problem” from part 3 above and provide the forecasts and prediction limits.  
```

#### Ensemble Model 
```{r ensemble model, eval = TRUE }
# ensemble model 

# plot of ARMA Model 
total_users = bike_data$`Total Users`
len_total_users = length(total_users)

plot(x= seq((len_total_users -182 ), len_total_users) , y = 
       total_users[(len_total_users -182 ): len_total_users], type='l')

lines(x= seq((len_total_users -182+1 ), len_total_users) , y = for_bike_arma$f,
      type= "l", col = 'blue')

lines(x= seq((len_total_users -182+1 ), len_total_users) , y = for_bike_arma$ll,
      type= "l", col = 'blue')

lines(x= seq((len_total_users -182+1 ), len_total_users) , y = for_bike_arma$ul,
      type= "l", col = 'blue')

# plot of the ARIMA model
total_users = bike_data$`Total Users`
len_total_users = length(total_users)

plot(x= seq((len_total_users -182 ), len_total_users) , y = 
       total_users[(len_total_users -182 ): len_total_users], type='l')
lines(x= seq((len_total_users -182 ), len_total_users) , y = 
        total_users[(len_total_users -182 ): len_total_users], type='l')

lines(x= seq((len_total_users -182+1 ), len_total_users) , y = for_bike_arima$f,
      type= "l", col='blue')

lines(x= seq((len_total_users -182+1 ), len_total_users) , y = for_bike_arima$ul,
      type= "l", col='blue')

lines(x= seq((len_total_users -182+1 ), len_total_users) , y = for_bike_arima$ll,
      type= "l", col='blue')

# plot of the VAR model 

t = c(1:182)
plot(t, preds$fcst$Total.Users[1:182],  type='l',col="blue", ylim=c(0,450))
lines(t, bikeTest$"Total Users",col="black")
lines(t, preds$fcst$Total.Users[183:364], col="blue")
lines(t, preds$fcst$Total.Users[365:546],  col="blue")

# plot of the NN 


total_users = bike_data$"Total Users"

plot(x= seq((len_total_users -182 ), len_total_users) , y = 
       total_users[(len_total_users -182 ): len_total_users], type='l')

lines(x= seq((len_total_users -182+1 ), len_total_users) , y = fore.mlp$mean,
      type= "l", col='blue')

# take top two models and average forcast. Then compute ASE. 

ensemble = ((preds$fcst$Total.Users[1:182] + for_bike_arma$f)/2)

# plot of ensemble

# plot of the ARIMA model
total_users = bike_data$`Total Users`
len_total_users = length(total_users)

plot(x= seq((len_total_users -182 ), len_total_users) , y = 
       total_users[(len_total_users -182 ): len_total_users], type='l')

lines(x= seq((len_total_users -182 ), len_total_users) , y = 
        total_users[(len_total_users -182 ): len_total_users], type='l')

lines(x= seq((len_total_users -182+1 ), len_total_users) , y = ensemble,
      type= "l", col='blue')

ASE_Ensemble = mean((ensemble-bikeTest$"Total Users")^2)
ASE_Ensemble

```

#### Model Comparision
```{r model comparison, eval = TRUE }

print("ASE for each model")
print(c("ARMA(2,1) ", as.integer(ASE_ARMA21)))
print(c('ARIMA(1,1,1,) ', as.integer(ASE2_ARIMA111)))
print(c("ARUMA(0,1,1) with s = 365", as.integer(ASE2_ARUMA011)))
print(c("VAR ", as.integer(ASE_VAR)))
print(c("NN", as.integer(ASE_NN)))
print(c("Ensemble", as.integer(ASE_Ensemble)))

```
 
